{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5D4n8Pk/d5xWJlVT1BaKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhigyan2003/keystroke/blob/main/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vidgz8znHoVe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "\n",
        "# Load both user files\n",
        "df1 = pd.read_csv(\"/content/User1.csv\")\n",
        "df2 = pd.read_csv(\"/content/User9.csv\")\n",
        "\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# Clean\n",
        "df = df[df['EventType'].isin(['press', 'release'])].dropna(subset=['Key', 'Username'])\n",
        "df = df.sort_values('Timestamp').reset_index(drop=True)\n",
        "\n",
        "# Encode key values and usernames\n",
        "key_encoder = LabelEncoder()\n",
        "user_encoder = LabelEncoder()\n",
        "\n",
        "df['KeyEncoded'] = key_encoder.fit_transform(df['Key'])\n",
        "df['UserEncoded'] = user_encoder.fit_transform(df['Username'])\n",
        "\n",
        "print(user_encoder.classes_)  # should print ['User1' 'User2']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-1Oox7AJsSu",
        "outputId": "9cb99f58-c05e-4f12-d647-90a5a44d059c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['User1' 'User9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_show = ['Timestamp', 'Key', 'EventType', 'Username']\n",
        "\n",
        "print(\"User1 Samples:\")\n",
        "print(df[df['Username'] == 'User1'][columns_to_show])\n",
        "\n",
        "print(\"\\nUser9 Samples:\")\n",
        "print(df[df['Username'] == 'User9'][columns_to_show])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_HC-zS0JxEu",
        "outputId": "4ffac3d5-3d8c-4ed4-ae66-76024e9546ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User1 Samples:\n",
            "                      Timestamp          Key EventType Username\n",
            "0       2017-03-20 01:25:20,894    Key.alt_l   release    User1\n",
            "1       2017-03-20 01:25:20,910   Key.ctrl_l   release    User1\n",
            "2       2017-03-20 01:25:20,910    Key.shift   release    User1\n",
            "3       2017-03-20 01:25:20,910      Key.cmd   release    User1\n",
            "4       2017-03-20 01:25:20,910    Key.alt_r   release    User1\n",
            "...                         ...          ...       ...      ...\n",
            "357100  2017-03-24 20:02:57,163  Key.shift_r   release    User1\n",
            "357101  2017-03-24 20:02:57,163    Key.cmd_r   release    User1\n",
            "357102  2017-03-24 20:02:57,927   Key.ctrl_l   release    User1\n",
            "357103  2017-03-24 20:02:57,927   Key.ctrl_l   release    User1\n",
            "357104  2017-03-24 20:02:57,943    Key.shift   release    User1\n",
            "\n",
            "[194326 rows x 4 columns]\n",
            "\n",
            "User9 Samples:\n",
            "                      Timestamp          Key EventType Username\n",
            "2661    2017-03-20 11:07:52,842   Key.ctrl_l   release    User9\n",
            "2662    2017-03-20 11:07:52,852   Key.ctrl_r   release    User9\n",
            "2663    2017-03-20 11:07:52,854    Key.shift   release    User9\n",
            "2664    2017-03-20 11:07:52,857  Key.shift_r   release    User9\n",
            "2665    2017-03-20 11:07:52,858    Key.alt_l   release    User9\n",
            "...                         ...          ...       ...      ...\n",
            "357132  2017-03-24 20:10:41,224        <241>   release    User9\n",
            "357133  2017-03-24 20:10:41,224   Key.ctrl_l   release    User9\n",
            "357134  2017-03-24 20:10:41,224   Key.ctrl_l   release    User9\n",
            "357135  2017-03-24 20:10:41,224    Key.shift   release    User9\n",
            "357136  2017-03-24 20:10:41,224        <234>   release    User9\n",
            "\n",
            "[162811 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîç Unique Event Types present in the data:\")\n",
        "print(df['EventType'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Sx6ygwJz1b",
        "outputId": "f092a684-0e46-453d-cf51-e15097a155c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Unique Event Types present in the data:\n",
            "['release' 'press']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîë Unique key values in the dataset:\")\n",
        "print(df['Key'].unique())\n",
        "print(\"\\nüî¢ Total number of unique keys:\")\n",
        "print(df['Key'].nunique())\n",
        "print(\"\\nüìä Frequency of each key (top 20):\")\n",
        "print(df['Key'].value_counts().head(10))  # show top 20 most used keys\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023U06ufJ2sj",
        "outputId": "b10ed479-77b4-4984-fd0f-22ad398fea02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîë Unique key values in the dataset:\n",
            "['Key.alt_l' 'Key.ctrl_l' 'Key.shift' 'Key.cmd' 'Key.alt_r' 'Key.ctrl_r'\n",
            " 'Key.shift_r' 'Key.cmd_r' \"u'LEFT'\" \"u'RIGHT'\" \"u'CENTER'\" \"u'None'\"\n",
            " 'Key.backspace' 'Key.space' 'Key.enter' \"u'DIGIT'\" 'Key.tab' 'Key.up'\n",
            " 'Key.down' 'Key.delete' 'Key.caps_lock' 'Key.right' 'Key.num_lock'\n",
            " 'Key.left' '<241>' '<234>' 'Key.end' 'Key.home' 'Key.f3' 'Key.esc'\n",
            " '<175>' '<174>' '<135>' '<47>' 'Key.f11' 'Key.f12' 'Key.f5' 'Key.f7']\n",
            "\n",
            "üî¢ Total number of unique keys:\n",
            "38\n",
            "\n",
            "üìä Frequency of each key (top 20):\n",
            "Key\n",
            "u'LEFT'          82575\n",
            "u'RIGHT'         69652\n",
            "u'CENTER'        65371\n",
            "Key.space        35395\n",
            "u'None'          22081\n",
            "Key.backspace    20993\n",
            "Key.shift        20594\n",
            "Key.ctrl_l       16396\n",
            "Key.enter         5329\n",
            "u'DIGIT'          3927\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 50\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(df) - SEQ_LEN):\n",
        "    keys = df['KeyEncoded'].iloc[i:i+SEQ_LEN].tolist()\n",
        "    users = df['UserEncoded'].iloc[i:i+SEQ_LEN]\n",
        "    if len(set(users)) == 1:  # one user per sequence\n",
        "        X.append(keys)\n",
        "        y.append(users.iloc[0])\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.long)\n",
        "y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}, Labels: {y.unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuYURbJtJ4cg",
        "outputId": "9241ac15-400f-412f-ec90-8b60443c17ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: torch.Size([282254, 50]), Labels: tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2) * -math.log(10000.0) / d_model)\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n"
      ],
      "metadata": {
        "id": "aK42ve5vJ70U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        H = self.num_heads\n",
        "\n",
        "        Q = self.q_linear(x).view(B, T, H, self.d_k).transpose(1, 2)  # (B, H, T, d_k)\n",
        "        K = self.k_linear(x).view(B, T, H, self.d_k).transpose(1, 2)\n",
        "        V = self.v_linear(x).view(B, T, H, self.d_k).transpose(1, 2)\n",
        "\n",
        "        scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)  # (B, H, T, T)\n",
        "        weights = torch.softmax(scores, dim=-1)\n",
        "        out = weights @ V  # (B, H, T, d_k)\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, D)\n",
        "        return self.out_proj(out)\n"
      ],
      "metadata": {
        "id": "iTOck530J9iy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, ff_dim=128, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, d_model)\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out = self.attn(x)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_out))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "0eV-eKrRJ_Av"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KeystrokeClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, num_classes, d_model=64, num_heads=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderBlock(d_model, num_heads) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x = self.pos_enc(x)\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "        x = x.mean(dim=1)  # Global mean pooling\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "LzQ3ysGuKAws"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Create dataset from tensors\n",
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# Sequential (non-random) split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_ds = TensorDataset(X[:train_size], y[:train_size])\n",
        "val_ds = TensorDataset(X[train_size:], y[train_size:])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=32)\n",
        "\n",
        "# Model, loss, and optimizer\n",
        "model = KeystrokeClassifier(vocab_size=len(key_encoder.classes_), num_classes=2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "HRnQMn6EKCqf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Convert y tensor to numpy for sklearn\n",
        "y_np = y.numpy()\n",
        "\n",
        "# Compute weights: make sure classes are in [0, 1, 2, ..., N]\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_np), y=y_np)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "X7_xElHEKESD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n"
      ],
      "metadata": {
        "id": "nnNl8yT-KF9P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After class_weights is calculated\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "model = KeystrokeClassifier(vocab_size=len(key_encoder.classes_), num_classes=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "Zgcd_QYnKH0h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Class Weights:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AvD12JCKJjx",
        "outputId": "543aed3c-1320-4c8a-8af2-3469e6c50e6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: tensor([0.9070, 1.1143])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm  # install with `pip install tqdm` if needed\n",
        "\n",
        "def train(model, train_dl, val_dl, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        print(f\"\\n--- Epoch {epoch+1} ---\")\n",
        "\n",
        "        progress_bar = tqdm(train_dl, desc=f\"Training\", leave=False)\n",
        "        for i, (xb, yb) in enumerate(progress_bar, 1):\n",
        "            preds = model(xb)\n",
        "            loss = loss_fn(preds, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            progress_bar.set_postfix(Step=i, Loss=loss.item())\n",
        "\n",
        "        # === Validation ===\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_dl:\n",
        "                preds = model(xb)\n",
        "                correct += (preds.argmax(dim=1) == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "\n",
        "        acc = correct / total\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch+1:2d} | Total Loss: {total_loss:.4f} | Val Acc: {acc:.2%} | Time: {epoch_time:.2f}s\")\n"
      ],
      "metadata": {
        "id": "YtYIyXmnKK8g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_dl, val_dl, epochs=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT_q4JESKMR-",
        "outputId": "b0b1c926-aab4-4d63-ca8f-7dcc33b47862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Epoch 1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  35%|‚ñà‚ñà‚ñà‚ñå      | 2487/7057 [01:41<02:29, 30.64it/s, Loss=0.614, Step=2490]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        out = model(xb)\n",
        "        preds = torch.argmax(out, dim=1)\n",
        "        y_true.extend(yb.tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=user_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "WH5VlQvvKOl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Run prediction loop again (required to define y_true and y_pred)\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        out = model(xb)\n",
        "        preds = torch.argmax(out, dim=1)\n",
        "        y_true.extend(yb.tolist())\n",
        "        y_pred.extend(preds.tolist())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "labels = user_encoder.classes_\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jDY5xHqjKSni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Count the number of samples for each user label\n",
        "unique_classes, counts = torch.unique(y, return_counts=True)\n",
        "\n",
        "# Decode class labels (assuming you used user_encoder to encode labels)\n",
        "for label, count in zip(unique_classes, counts):\n",
        "    print(f\"{user_encoder.inverse_transform([label.item()])[0]}: {count.item()} samples\")\n"
      ],
      "metadata": {
        "id": "9vRPk93vKUOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "PkDACpYJKV3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchinfo import summary\n",
        "vocab_size = len(key_encoder.classes_)     # Number of unique keys\n",
        "num_classes = len(user_encoder.classes_)   # Number of users (classes)\n",
        "sequence_length = 20                       # As used during sequence creation\n",
        "\n",
        "model = KeystrokeClassifier(vocab_size, num_classes)\n",
        "\n",
        "summary(model, input_size=(1, sequence_length), dtypes=[torch.long])\n"
      ],
      "metadata": {
        "id": "NCOEvlzzKYid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def check_distribution(dl, name):\n",
        "    all_labels = []\n",
        "    for _, yb in dl:\n",
        "        all_labels.extend(yb.tolist())\n",
        "    dist = Counter(all_labels)\n",
        "    print(f\"{name} class distribution:\", {user_encoder.inverse_transform([k])[0]: v for k, v in dist.items()})\n",
        "\n",
        "print(f\"Training Set Size: {len(train_ds)} | Validation Set Size: {len(val_ds)}\")\n",
        "check_distribution(train_dl, \"Train\")\n",
        "check_distribution(val_dl, \"Validation\")\n"
      ],
      "metadata": {
        "id": "k-K6k4HMKYyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Filter original DataFrame for only User1\n",
        "user_name = 'User1'  # change if testing a different user\n",
        "user_label = user_encoder.transform([user_name])[0]\n",
        "user1_df = df[df['UserEncoded'] == user_label]\n",
        "\n",
        "# Select 5 random sequential samples from User1\n",
        "SEQ_LEN = 20  # or your sequence length\n",
        "num_samples = 5\n",
        "\n",
        "print(f\"\\n--- Predictions for User {user_name} ---\")\n",
        "for i in range(num_samples):\n",
        "    start_idx = torch.randint(0, len(user1_df) - SEQ_LEN, (1,)).item()\n",
        "    segment = user1_df.iloc[start_idx : start_idx + SEQ_LEN]\n",
        "    key_seq = torch.tensor([segment['KeyEncoded'].tolist()], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(key_seq)\n",
        "        pred_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    pred_user = user_encoder.inverse_transform([pred_class])[0]\n",
        "    print(f\"True: {user_name} | Predicted: {pred_user}\")\n"
      ],
      "metadata": {
        "id": "ypZ8i9v2KaWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Put model in eval mode and move to device\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "y_true = []\n",
        "y_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        outputs = model(xb)\n",
        "        probs = torch.softmax(outputs, dim=1)[:, 1]  # probability for class 'User9'\n",
        "\n",
        "        y_true.extend(yb.cpu().tolist())\n",
        "        y_probs.extend(probs.cpu().tolist())\n",
        "\n",
        "# Calculate AUC\n",
        "auc = roc_auc_score(y_true, y_probs)\n",
        "print(f\"AUC Score: {auc:.4f}\")\n",
        "\n",
        "# === Plot ROC Curve ===\n",
        "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random baseline\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qqZdeAVjKb9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfBAYBCpKdid"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}